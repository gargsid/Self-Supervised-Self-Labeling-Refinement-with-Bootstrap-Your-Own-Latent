# Self-Supervised-Self-Labeling-Refinement-with-Bootstrap-Your-Own-Latent
Self Labeling Refinement procedure in Self-Supervised framework Bootstrap Your Own Latent (BYOL)

Introduced two new loss functions for learning robust image representations for doing self-labeling refinement. 

1. Cross-cosine Similarity Loss (CCSL)
2. Cross-Sigmoid Similarity Loss (CSSL)

Following are the screenshots from the paper

<p float="left">
  <img src="https://github.com/gargsid/Self-Supervised-Self-Labeling-Refinement-with-Bootstrap-Your-Own-Latent/blob/main/assets/byol_plots.png" width="1000" height="300" />
</p> 

<img src="https://github.com/gargsid/Self-Supervised-Self-Labeling-Refinement-with-Bootstrap-Your-Own-Latent/blob/main/assets/byol_table.png" width="500" height="400" />

As we can see that the proposed loss functions, CCSL and CSSL are outperforming the vanilla BYOL setup on STL classification dataset for linear evaluation protocol. 
